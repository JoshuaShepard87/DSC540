{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab13ceac-08da-47f0-b283-ff082c5f77de",
   "metadata": {},
   "source": [
    "# Weeks 7 & 8\n",
    "\n",
    "- Joshua Burden\n",
    "- Bellevue University\n",
    "- DSC540 Data Preparation\n",
    "- Cathrine Williams\n",
    "- 07/31/2022\n",
    "\n",
    "\n",
    "### Complete the following exercises. You can submit a Jupyter Notebook or a PDF of your code. If you submit a .py file you need to also include a PDF or attachment of your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afb62e-5cba-45fa-8d6b-68b5f6b917aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Wrangling with Python: Activity 9, page 294\n",
    "\n",
    "# What is Project Gutenberg? -\n",
    "Project Gutenberg is a volunteer effort to digitize and archive cultural works, to \"encourage the creation and distribution of eBooks\". It was founded in 1971 by American writer Michael S. Hart and is the oldest digital library. This longest-established ebook project releases books that entered the public domain, and can be freely read or downloaded in various electronic formats.\n",
    "\n",
    "# What is this activity all about?\n",
    "- This activity aims to scrape the url of the Project Gutenberg's Top 100 ebooks (yesterday's ranking) for identifying the ebook links.\n",
    "- It uses BeautifulSoup4 for parsing the HTML and regular expression code for identifying the Top 100 ebook file numbers.\n",
    "- You can use those book ID numbers to download the book into your local drive if you want\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc40e4-22a8-4e6e-97f6-c38e7a466d97",
   "metadata": {},
   "source": [
    "# Import necessary libraries including regex, and beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c1e739-9f20-4f4e-95ba-f85648907dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07883946-45c7-4b87-8da9-d366294f592f",
   "metadata": {},
   "source": [
    "# Ignore SSL errors (this code will be given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "003cdad8-c3ca-480d-955b-0fa940f4c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20346563-f58c-4a2d-b952-7eba8bcae92d",
   "metadata": {},
   "source": [
    "# Read the HTML from the URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60f87c60-c426-4b68-b77e-0b1ca49d399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HTML from the URL and pass on to BeautifulSoup\n",
    "top100url = 'https://www.gutenberg.org/browse/scores/top'\n",
    "response = requests.get(top100url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0672143d-7350-4303-8913-f306f014338f",
   "metadata": {},
   "source": [
    "# Write a small function to check the status of web request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d192d5ac-7d3b-415a-a2ef-637afb05aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_check(r):\n",
    "    if r.status_code==200:\n",
    "        print(\"Success!\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Failed!\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "753b3975-2ace-4b01-a1e2-e16b432d28b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_check(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8946da9-c78c-42e7-83d4-123141e08c14",
   "metadata": {},
   "source": [
    "# Decode the response and pass on to BeautifulSoup for HTML parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1911400d-ae29-42f4-b4d6-228240a2108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = response.content.decode(response.encoding)\n",
    "soup = BeautifulSoup(contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e64353-560b-47fe-b6f8-b52fcd414889",
   "metadata": {},
   "source": [
    "# Find all the href tags and store them in the list of links. Check how the list looks like - print first 30 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "255c6a90-333c-4a8f-8f8c-163dcac296e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to hold all the http links in the HTML page\n",
    "lst_links=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3381e92-4dd3-48c1-a531-a1974b3cc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the href tags and store them in the list of links\n",
    "for link in soup.find_all('a'):\n",
    "    #print(link.get('href'))\n",
    "    lst_links.append(link.get('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "783f84a5-93f0-442e-b236-17d4ae63b034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/about/',\n",
       " '/about/',\n",
       " '/policy/collection_development.html',\n",
       " '/about/contact_information.html',\n",
       " '/about/background/',\n",
       " '/policy/permission.html',\n",
       " '/policy/privacy_policy.html',\n",
       " '/policy/terms_of_use.html',\n",
       " '/ebooks/',\n",
       " '/ebooks/',\n",
       " '/ebooks/bookshelf/',\n",
       " '/browse/scores/top',\n",
       " '/ebooks/offline_catalogs.html',\n",
       " '/help/',\n",
       " '/help/',\n",
       " '/help/copyright.html',\n",
       " '/help/errata.html',\n",
       " '/help/file_formats.html',\n",
       " '/help/faq.html',\n",
       " '/policy/',\n",
       " '/help/public_domain_ebook_submission.html',\n",
       " '/help/submitting_your_own_work.html',\n",
       " '/help/mobile.html',\n",
       " '/attic/',\n",
       " '/donate/',\n",
       " '/donate/',\n",
       " '#books-last1',\n",
       " '#authors-last1',\n",
       " '#books-last7']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_links[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794bd57-32c1-4d2b-b144-cac00fbf4083",
   "metadata": {},
   "source": [
    "# Use regular expression to find the numeric digits in these links. These are the file number for the Top 100 books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96612452-944e-49c7-bd03-132e60c898ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list to hold the file numbers\n",
    "booknum=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d1047-7fbb-4acf-8b8b-afcebc3ac386",
   "metadata": {},
   "source": [
    "- Number 19 to 118 in the original list of links have the Top 100 ebooks' number.\n",
    "- Loop over appropriate range and use regex to find the numeric digits in the link (href) string.\n",
    "- Hint: Use findall() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7da0acc3-4900-4784-b32b-6034a800e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(19,119):\n",
    "    link=lst_links[i]\n",
    "    link=link.strip()\n",
    "    # Regular expression to find the numeric digits in the link (href) string\n",
    "    n=re.findall('[0-9]+',link)\n",
    "    if len(n)==1:\n",
    "        # Append the filenumber casted as integer\n",
    "        booknum.append(int(n[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4315ec1-246f-4607-a07d-2aaffb658338",
   "metadata": {},
   "source": [
    "# Print the file numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f7eb702-cd09-4aee-a59c-947f5901d1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The file numbers for the top 100 ebooks on Gutenberg are shown below\n",
      "----------------------------------------------------------------------\n",
      "[1, 1, 7, 7, 30, 30, 1342, 4300, 1661, 11, 33283, 105, 2701, 68639, 345, 174, 1184, 98, 68641, 84, 68642, 2600, 2554, 2591, 5200, 6130, 1952, 30254, 64317, 1400, 768, 1260, 45, 1080, 4980, 38600, 68640, 32449, 76, 74, 1232, 120, 158, 27827, 58585, 514, 844, 1399, 28054, 996, 135, 35, 4363, 5740, 43, 2680, 46, 1497, 67098, 43453, 205, 16, 161, 25717, 219, 3206, 244, 10, 31284, 36, 68636, 27107, 55, 8492, 68638, 2852, 766, 2848, 2542, 2814, 730, 41, 68646, 863, 408, 1998, 8800, 236, 10007, 1727, 113, 68650]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"\\nThe file numbers for the top 100 ebooks on Gutenberg are shown below\\n\"+\"-\"*70)\n",
    "print(booknum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e0b26-f181-45f5-b87e-e6dd236f2ab3",
   "metadata": {},
   "source": [
    "# How does the soup object's text look like? Use .text() method and print only first 2000 characters (i.e. do not print the whole thing, it is long).\n",
    "You will notice lot of empty spaces/blanks here and there. Ignore them. They are part of HTML page markup and its whimsical nature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cb608e5-4d3c-405c-bd54-d4623d022a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 100 | Project Gutenberg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Menu▾\n",
      "\n",
      "\n",
      "\n",
      "About\n",
      "          ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "About Project Gutenberg\n",
      "Collection Development\n",
      "Contact Us\n",
      "History & Philosophy\n",
      "Permissions & License\n",
      "Privacy Policy\n",
      "Terms of Use\n",
      "\n",
      "\n",
      "\n",
      "Search and Browse\n",
      "      \t  ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "Book Search\n",
      "Bookshelves\n",
      "Frequently Downloaded\n",
      "Offline Catalogs\n",
      "\n",
      "\n",
      "\n",
      "Help\n",
      "          ▾\n",
      "\n",
      "▾\n",
      "\n",
      "\n",
      "All help topics →\n",
      "Copyright Procedures\n",
      "Errata, Fixes and Bug Reports\n",
      "File Formats\n",
      "Frequently Asked Questions\n",
      "Policies →\n",
      "Public Domain eBook Submission\n",
      "Submitting Your Own Work\n",
      "Tablets, Phones and eReaders\n",
      "The Attic →\n",
      "\n",
      "\n",
      "Donate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Donation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Frequently Viewed or Downloaded\n",
      "These listings are based on the number of times each eBook gets downloaded.\n",
      "      Multiple downloads from the same Internet address on the same day count as one download, and addresses that download more than 100 eBooks in a day are considered robots and are not counted.\n",
      "\n",
      "Downloaded Books\n",
      "2022-07-30166339\n",
      "last 7 days1089191\n",
      "last 30 days4465455\n",
      "\n",
      "\n",
      "\n",
      "Top 100 EBooks yesterday\n",
      "Top 100 Authors yesterday\n",
      "Top 100 EBooks last 7 days\n",
      "Top 100 Authors last 7 days\n",
      "Top 100 EBooks last 30 days\n",
      "Top 100 Authors last 30 days\n",
      "\n",
      "\n",
      "Top 100 EBooks yesterday\n",
      "\n",
      "Pride and Prejudice by Jane Austen (1411)\n",
      "Ulysses by James Joyce (1386)\n",
      "The Adventures of Sherlock Holmes by Arthur Conan Doyle (771)\n",
      "Alice's Adventures in Wonderland by Lewis Carroll (640)\n",
      "Calculus Made Easy by Silvanus P.  Thompson (602)\n",
      "Persuasion by Jane Austen (597)\n",
      "Moby Dick; Or, The Whale by Herman Melville (524)\n",
      "Poems we all love by Various Various (511)\n",
      "Dracula by Bram Stoker (462)\n",
      "The Picture of Dorian Gray by Oscar Wilde (461)\n",
      "The Count of Monte Cristo, Illustrated by Alexandre Dumas (406)\n",
      "A Tale of Two Cities by Charles Dickens (400)\n",
      "The descent of the Sun: A cycle of birth by Unknown Unknown (398)\n",
      "Frankenstein; Or, The Modern Prometheus by Mary Wollstonecraft Shelley (395)\n",
      "The little white gate by Florence Hoatson (388)\n",
      "War and Peace by graf Leo Tolstoy (376)\n",
      "Crime and Punishment by Fyodor Dostoyevsky (370)\n"
     ]
    }
   ],
   "source": [
    "print(soup.text[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa32f9-e60e-49d9-8d1b-fc6cf90c9130",
   "metadata": {},
   "source": [
    "# Search in the extracted text (using regular expression) from the soup object to find the names of top 100 Ebooks (Yesterday's rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "feaf634f-9bb9-479b-8943-0d8390aaaaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp empty list of Ebook names\n",
    "lst_titles_temp=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823b143-d793-4457-9904-2cad70260674",
   "metadata": {},
   "source": [
    "# Create a starting index. It should point at the text \"Top 100 Ebooks yesterday\". Hint: Use splitlines() method of the soup.text. It splits the lines of the text of the soup object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02919334-6918-4fc4-b1bb-3c2f6b3b9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx=soup.text.splitlines().index('Top 100 EBooks yesterday')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee2354-852c-4dac-ab01-1736cd465623",
   "metadata": {},
   "source": [
    "# Loop 1-100 to add the strings of next 100 lines to this temporary list.\n",
    "- Hint: splitlines() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e0c37ec-89d2-4fb1-9223-c3a9ae50ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    lst_titles_temp.append(soup.text.splitlines()[start_idx+2+i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d6b1b-1464-4b20-a404-384fc261a438",
   "metadata": {},
   "source": [
    "# Use regular expression to extract only text from the name strings and append to an empty list\n",
    "- Hint: Use match and span to find indices and use them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94a35e81-0bc2-4f83-8764-c8da06bbdff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_titles=[]\n",
    "for i in range(100):\n",
    "    id1,id2=re.match('^[a-zA-Z ]*',lst_titles_temp[i]).span()\n",
    "    lst_titles.append(lst_titles_temp[i][id1:id2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb43f01-382a-42ab-8fba-511b7279c88a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Print the list of titles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c073b-d17e-4973-bf71-10b418acdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in lst_titles:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46483e-4745-4199-9a13-e24585e97a1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Wrangling with Python: Activity 10, page 295\n",
    "### Build your own movie database by reading from an API\n",
    "This notebook does the following\n",
    "- Retrieves and prints basic data about a movie (title entered by user) from the web (OMDB database)\n",
    "- If a poster of the movie could be found, it downloads the file and saves at a user-specified location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc7934ba-ec28-42a1-8975-d04baaf0b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f77e97-59bb-4f14-ac23-f287f413e07c",
   "metadata": {},
   "source": [
    "# Load the secret API key (you have to get one from OMDB website and use that, 1000 daily limit) from a JSON file, stored in the same folder into a variable\n",
    "- Hint: Use json.loads()\n",
    "\n",
    "Note: The following cell will not be executed in the solution notebook because the author cannot give out his private API key.\n",
    "#### Students/users/instructor will need to obtain a key and store in a JSON file.\n",
    "#### For the code's sake, we are calling this file APIkeys.json. But you need to store your own key in this file.\n",
    "#### An example file called \"APIkey_Bogus_example.json\" is given along with the notebook. Just change the code in this file and rename as APIkeys.json. The file name does not matter of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6362bd97-b745-4fc5-9926-c8171bbc814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('APIkeys.json') as f:\n",
    "    keys = json.load(f)\n",
    "    omdbapi = keys['OMDBapi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed7189-d08a-47be-9e63-46fdaa1401e8",
   "metadata": {},
   "source": [
    "Do the following,\n",
    "\n",
    "- Assign the OMDB portal (http://www.omdbapi.com/?) as a string to a variable serviceurl (don't miss the ?)\n",
    "- Create a variable apikey with the last portion of the URL (\"&apikey=secretapikey\"), where secretapikey is your own API key (an actual code)\n",
    "- The movie name portion i.e. \"t=movie_name\" will be addressed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "108205fe-e3b9-4d94-bfb2-ac38e5ad5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "serviceurl = 'http://www.omdbapi.com/?'\n",
    "apikey = '&apikey='+omdbapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6d986-1ec6-4bfa-bc82-4ac7aea0383d",
   "metadata": {},
   "source": [
    "# Write a utility function print_json to print nicely the movie data from a JSON file (which we will get from the portal)\n",
    "Here are the keys of a JSON file,\n",
    "\n",
    "'Title', 'Year', 'Rated', 'Released', 'Runtime', 'Genre', 'Director', 'Writer', 'Actors', 'Plot', 'Language','Country', 'Awards', 'Ratings', 'Metascore', 'imdbRating', 'imdbVotes', 'imdbID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d40813e-cc5d-4f8c-a19e-b35e8fd26d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_json(json_data):\n",
    "    list_keys=['Title', 'Year', 'Rated', 'Released', 'Runtime', 'Genre', 'Director', 'Writer', \n",
    "               'Actors', 'Plot', 'Language', 'Country', 'Awards', 'Ratings', \n",
    "               'Metascore', 'imdbRating', 'imdbVotes', 'imdbID']\n",
    "    print(\"-\"*50)\n",
    "    for k in list_keys:\n",
    "        if k in list(json_data.keys()):\n",
    "            print(f\"{k}: {json_data[k]}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6307f-ad61-40cf-aed3-425c014c0764",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Write a utility function to download a poster of the movie based on the information from the jason dataset and save in your local folder\n",
    "- Use os module\n",
    "- The poster data is stored in the JSON key 'Poster'\n",
    "- You may want to split the name of the Poster file and extract the file extension only. Let's say the extension is 'jpg'.\n",
    "- Then later join this extension to the movie name and create a filename like movie.jpg\n",
    "- Use the Python command open to open a file and write the poster data. Close the file after done.\n",
    "- This function may not return anything. It just saves the poster data as an image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ad5870a-4d8d-4085-8342-0cebdbc88143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_poster(json_data):\n",
    "    import os\n",
    "    title = json_data['Title']\n",
    "    poster_url = json_data['Poster']\n",
    "    # Splits the poster url by '.' and picks up the last string as file extension\n",
    "    poster_file_extension=poster_url.split('.')[-1]\n",
    "    # Reads the image file from web\n",
    "    poster_data = urllib.request.urlopen(poster_url).read()\n",
    "        \n",
    "    savelocation=os.getcwd()+'//'+'Posters'+'//'\n",
    "    # Creates new directory if the directory does not exist. Otherwise, just use the existing path.\n",
    "    if not os.path.isdir(savelocation):\n",
    "        os.mkdir(savelocation)\n",
    "    \n",
    "    filename=savelocation+str(title)+'.'+poster_file_extension\n",
    "    f=open(filename,'wb')\n",
    "    f.write(poster_data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1dc8d-e303-493e-87f1-f89fd0fe54a0",
   "metadata": {},
   "source": [
    "# Write a utility function search_movie to search a movie by its name, print the downloaded JSON data (use the print_json function for this) and save the movie poster in the local folder (use save_poster function for this)\n",
    "- Use try-except loop for this i.e. try to connect to the web portal, if successful proceed but if not (i.e. exception raised) then just print an error message\n",
    "- Here use the previously created variables serviceurl and apikey\n",
    "- You have to pass on a dictionary with a key t and the movie name as the corresponding value to urllib.parse.urlencode() function and then add the serviceurl and apikey to the output of the function to construct the full URL\n",
    "- This URL will be used for accessing the data\n",
    "- The JSON data has a key called Response. If it is True, that means the read was successful. Check this before processing the data. If not successful, then print the JSON key Error, which will contain the appropriate error message returned by the movie database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8993e6c-0dbe-4f95-85f3-52066dbbe095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_movie(title):\n",
    "    try:\n",
    "        url = serviceurl + urllib.parse.urlencode({'t': str(title)})+apikey\n",
    "        print(f'Retrieving the data of \"{title}\" now... ')\n",
    "        print(url)\n",
    "        uh = urllib.request.urlopen(url)\n",
    "        data = uh.read()\n",
    "        json_data=json.loads(data)\n",
    "        \n",
    "        if json_data['Response']=='True':\n",
    "            print_json(json_data)\n",
    "            # Asks user whether to download the poster of the movie\n",
    "            if json_data['Poster']!='N/A':\n",
    "                save_poster(json_data)\n",
    "        else:\n",
    "            print(\"Error encountered: \",json_data['Error'])\n",
    "    \n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"ERROR: {e.reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dde051-2377-4c93-805e-710502d1ef9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test search_movie function by entering Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4e8a090-fd93-487f-af29-5276300da0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving the data of \"Titanic\" now... \n",
      "http://www.omdbapi.com/?t=Titanic&apikey=b5a31683\n",
      "--------------------------------------------------\n",
      "Title: Titanic\n",
      "Year: 1997\n",
      "Rated: PG-13\n",
      "Released: 19 Dec 1997\n",
      "Runtime: 194 min\n",
      "Genre: Drama, Romance\n",
      "Director: James Cameron\n",
      "Writer: James Cameron\n",
      "Actors: Leonardo DiCaprio, Kate Winslet, Billy Zane\n",
      "Plot: A seventeen-year-old aristocrat falls in love with a kind but poor artist aboard the luxurious, ill-fated R.M.S. Titanic.\n",
      "Language: English, Swedish, Italian, French\n",
      "Country: United States\n",
      "Awards: Won 11 Oscars. 125 wins & 83 nominations total\n",
      "Ratings: [{'Source': 'Internet Movie Database', 'Value': '7.9/10'}, {'Source': 'Rotten Tomatoes', 'Value': '87%'}, {'Source': 'Metacritic', 'Value': '75/100'}]\n",
      "Metascore: 75\n",
      "imdbRating: 7.9\n",
      "imdbVotes: 1,147,994\n",
      "imdbID: tt0120338\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "search_movie(\"Titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7837fa-54dd-4b9b-b3d0-8dc3cc0a3d5c",
   "metadata": {},
   "source": [
    "# Test search_movie function by entering \"Random_error\" (obviously this will not be found and you should be able to check whether your error catching code is working properly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1a121bce-f68e-4238-874a-afa7d3dc5ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving the data of \"Random_error\" now... \n",
      "http://www.omdbapi.com/?t=Random_error&apikey=b5a31683\n",
      "Error encountered:  Movie not found!\n"
     ]
    }
   ],
   "source": [
    "search_movie(\"Random_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf1aa0-f395-4a0c-ac8b-915d32440203",
   "metadata": {},
   "source": [
    "# Look for a folder called 'Posters' in the same directory you are working in. It should contain a file called 'Titanic.jpg'. Open and see if the poster came alright!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51506d8c-1b63-438c-8b31-818df8c2adbc",
   "metadata": {},
   "source": [
    "# Connect to the Twitter API and do a simple data pull\n",
    "- a. If you don’t have a twitter account – create one at twitter.com/signup (you can delete the account after this assignment)\n",
    "- b. Sign in to apps.twitter.com\n",
    "- c. Click “Create New App”\n",
    "- d. Give your app a name and description\n",
    "- e. Agree to the developer agreement – you will want to make sure to indicate this is for a class project, and this step can take several days to get through, so don’t wait until the last minute to complete this portion of the assignment\n",
    "- f. Create an access token\n",
    "- g. You should receive a consumer key and a token\n",
    "- h. Using either the instructions from the book on connecting to an API or for help look here – pull back data searching for “Bellevue University” and “Data Science” (or something else you are interested in)\n",
    "- i. How to Create a Twitter App and API Interface via Python. (Grogan, 2016)\n",
    "- ii. Welcome Python-Twitter’s Documentation!  (The Python-Twitter Developers, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b37ef431-3839-4b81-b22a-eded24653e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twilio\n",
      "  Downloading twilio-7.12.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /Users/joshua/opt/anaconda3/lib/python3.9/site-packages (from twilio) (2.28.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /Users/joshua/opt/anaconda3/lib/python3.9/site-packages (from twilio) (2.1.0)\n",
      "Requirement already satisfied: pytz in /Users/joshua/opt/anaconda3/lib/python3.9/site-packages (from twilio) (2021.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/joshua/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joshua/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (3.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/joshua/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joshua/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.0.0->twilio) (2022.5.18.1)\n",
      "Installing collected packages: twilio\n",
      "Successfully installed twilio-7.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66d2a7c8-2f56-4c65-b260-9fce51393947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Data Pull\n",
    "\n",
    "\n",
    "# Import required packages\n",
    "\n",
    "import oauth2\n",
    "import json\n",
    "import tweepy\n",
    "import dataset\n",
    "import oauth2\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from twilio.rest import Client\n",
    "\n",
    "\n",
    "API_KEY = 'ubBCcRayjnqZKAeiff14oMcuI'\n",
    "API_SECRET = 'ij5ezXCLDgMYafkhCoccnKhwKlFNcaefIUCrrdhBKk8TIjw5tK'\n",
    "TOKEN_KEY = '1553865885567401984-HN5vc9fS1WBp9BWYcKhvtBZTYeJfDB'\n",
    "TOKEN_SECRET = 'WeKJSQZJDXb858CiFHDytuGmst5nYGN9gVPBpP7UwPeSz'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed1cf3c-1901-4063-a3bb-daf36a434277",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'oauth2' has no attribute 'Consumer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ct/l8y_jb751b1ghqz7j4qhxv580000gn/T/ipykernel_39139/2072034427.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://api.twitter.com/1.1/search/tweets.json?q=%23childlabor'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moauthReq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOKEN_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOKEN_SECRET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/data/data.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ct/l8y_jb751b1ghqz7j4qhxv580000gn/T/ipykernel_39139/2072034427.py\u001b[0m in \u001b[0;36moauthReq\u001b[0;34m(url, key, secret, http_method, post_body, http_headers)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moauthReq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_body\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mb\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mconsumer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moauth2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConsumer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAPI_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAPI_SECRET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moauth2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moauth2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsumer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     resp, content = client.request(url, method=http_method,\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'oauth2' has no attribute 'Consumer'"
     ]
    }
   ],
   "source": [
    "def oauthReq(url, key, secret, http_method=\"GET\", post_body=b\"\", http_headers=None):\n",
    "    consumer = oauth2.Consumer(key=API_KEY, secret=API_SECRET)\n",
    "    token = oauth2.Token(key=key, secret=secret)\n",
    "    client = oauth2.Client(consumer, token)\n",
    "    resp, content = client.request(url, method=http_method,\n",
    "                                   body=post_body, headers=http_headers)\n",
    "    return content\n",
    "\n",
    "\n",
    "url = 'https://api.twitter.com/1.1/search/tweets.json?q=%23childlabor'\n",
    "data = oauthReq(url, TOKEN_KEY, TOKEN_SECRET)\n",
    "\n",
    "with open(\"/data/data.json\", \"wb\") as data_file:\n",
    "    data_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eebbfd2-d731-42d2-bd49-551ab97e409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the json file wrote\n",
    "import os\n",
    "\n",
    "files = os.listdir()\n",
    "\n",
    "if 'tweet_data.json' in files:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfba7347-458d-4f99-a956-8362ae70a500",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'API' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ct/l8y_jb751b1ghqz7j4qhxv580000gn/T/ipykernel_39139/2359902109.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'#childlabor'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# iterate through pages and save the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'API' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import dataset\n",
    "\n",
    "def store_tweet(item):\n",
    "    db = dataset.connect('sqlite:///data_wranfling.db')\n",
    "    # table = db['tweets']\n",
    "    table = db.create_table('tweets', primary_id=False)\n",
    "    item_json = item._json.copy()\n",
    "\n",
    "    for k, v in item_json.items():\n",
    "        if isinstance(v, dict):\n",
    "            item_json[k] = str(v)\n",
    "    \n",
    "    table.insert(item_json)\n",
    "\n",
    "# set the OAuth and access token\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(TOKEN_KEY, TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "query = '#childlabor'\n",
    "cursor = tweepy.Cursor(api.search, q=query, lanf=\"en\")\n",
    "\n",
    "# iterate through pages and save the data\n",
    "for page in cursor.pages():\n",
    "    for item in page:\n",
    "        store_tweet(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa42d2a3-bc9c-4d5c-9dfb-9cae0c865a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the database wrote\n",
    "import os\n",
    "\n",
    "files = os.listdir()\n",
    "\n",
    "if 'data_wranfling.db' in files:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbaacf86-f95a-469c-8f9f-c868bd8e3be8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StreamListener' from 'tweepy.streaming' (/Users/joshua/opt/anaconda3/lib/python3.9/site-packages/tweepy/streaming.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ct/l8y_jb751b1ghqz7j4qhxv580000gn/T/ipykernel_39139/3540325520.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStreamListener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtweepy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOAuthHandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStreamListener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSelf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StreamListener' from 'tweepy.streaming' (/Users/joshua/opt/anaconda3/lib/python3.9/site-packages/tweepy/streaming.py)"
     ]
    }
   ],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler, Stream\n",
    "\n",
    "class Listener(StreamListener):\n",
    "    def on_data(Self,data):\n",
    "        print(data)\n",
    "        return True\n",
    "\n",
    "auth = OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(TOKEN_KEY, TOKEN_SECRET)\n",
    "\n",
    "stream = Stream(auth, Listener())\n",
    "stream.filter(track=['child labor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472d4e8-e6c1-452a-b3f0-274676625e0d",
   "metadata": {},
   "source": [
    "# Using one of the datasets provided, or a dataset of your own, choose 3 of the following visualizations to complete. You must submit via PDF along with your code. You are free to use Matplotlib, Seaborn or another package if you prefer.\n",
    "- a. Line\n",
    "- b. Scatter\n",
    "- c. Bar\n",
    "- d. Histogram\n",
    "- e. Density Plot\n",
    "- f. Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab95e95e-1913-4563-b84f-09b994f73502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eefb59-e5ca-447c-b0b5-cc64d960ad36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ee097-57ba-4c4f-8607-3566e20cd316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16624da0-07bd-435a-a595-a90fb9d311f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2bbe7-b336-4724-996c-7431ac14aeff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11debec-bf06-4a2c-aa91-dbb3e9aa46ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96947bb-004d-4245-a6e4-86e38c6070c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb52fea-7f36-477f-85ba-5c3282b13c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d3baa-0aeb-4a4f-8114-9838106e7357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429a406-fa0b-48cc-896e-fffd1f20f59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9a50e-6d4b-4555-b464-966a05af3582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22f622-6ad1-4535-88d1-17f11999c572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c540b-94b6-4541-93b2-7087bff73a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c581738-5bcb-4764-acf1-a57455396429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae8647-af31-4839-9036-d4a94c85825c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d410101e-a1ef-47cc-be35-0dfe517c2818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
